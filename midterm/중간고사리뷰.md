### 배운 내용과 오류 발생 내용들
너무 너무 많았지만, 몇 가지를 추려보면..

1. **KAGGLE**
세상에 이렇게나 많은 데이터가 존재하는구나 깨달았고, 이 데이터를 꼭 써보고 싶다는 생각이 들었다.
2. **CSV 파일 MariaDB로 import 하기**
그 중에서도 가져오고 싶은 데이터는 youtube 데이터였다. 구글링을 통해 가져오는 방법을 찾고 (LODA DATE 이용) 입력했는데, 계속 오류가 났다. 특히 "칼럼의 개수보다 데이터가 더 많습니다" 라는 에러가 계속해서 출력되었다. 분명히 데이터셋과 동일한 칼럼을 가진 테이블을 만들어두었는데도 말이다.  
여러 자료와 삽질 끝에 에러의 원인을 알 수 있었다. 데이터를 LOAD 해올 때 구분자를 ","로 하여 가져오는데, 내가 가지고 있는 데이터셋은 "비디오 타이틀" "해시태그" 등에 구분자가 아닌 ","을 포함하고 있기 때문이였다.  
ex. ![image](https://user-images.githubusercontent.com/69361613/97793154-71011580-1c2b-11eb-86ba-771d3088a77a.png)
이를 테면 이런 것..^^ 
","를 다른 문자로 치환하는 방법을 생각해보았지만 원본 데이터를 훼손시키고 싶지 않아 csv 파일을 열어보았다.
![image](https://user-images.githubusercontent.com/69361613/97793169-b9203800-1c2b-11eb-995b-f5339942586d.png)
자세히 보니 데이터 제공자가 이러한 경우를 대비하여 데이터에 ,를 포함하는 경우 해당 데이터를 따옴표("")로 묶어논 것을 확인할 수 있었다. 그래서 LOAD DATA에 ENCLOSED BY '"' 을 추가했고, 성공적으로 데이터를 가져올 수 있었다.
~~~sql 
#사용한 쿼리
LOAD DATA INFILE '/var/www/html/db/krdata.csv' REPLACE INTO TABLE `youtube`.`KR` COLUMNS TERMINATED BY ',' ENCLOSED BY '"' LINES TERMINATED BY '\r\n' IGNORE 1 LINES (video_id, title, pulishedAt, channelId, channelTitle, categoryId, trending_date,tags, view_count, likes, dislikes, comment_count, thumbnail_link);
~~~
3. **링크를 연결하고 싶은데 데이터셋엔 없다.**
실제 유투브 비디오까지 연결이 되야 더 유의미한 데이터라고 생각을 해서 링크를 걸고 싶었는데 사용하고자 하는 데이터셋에는 유투브 링크를 제공하지 않고 있었다. 
그런데 제공되는 video_Id값이 알파벳+숫자 조합의 스트링이였는데, 이걸 통해서 유투브로 연결하는 링크를 만들 수 있을 거라고 생각이 들어 유투브 링크를 확인해본 결과 예상대로 링크에는 일정한 패턴이 존재했기 때문에 기본값 + 비디오 아이디를 연결하여 링크를 만들 수 있었다. 이렇게..
![image](https://user-images.githubusercontent.com/69361613/97793260-1c5e9a00-1c2d-11eb-99ba-9e2010fb2ee3.png)

4. **중복 데이터가 너무 많다.**
해당 데이터가 "일별 트렌딩 비디오" 데이터라는 걸 간과했다. 오늘 인기있는 비디오가 내일도 인기있는 비디오라면 두 날짜 모두에 트렌딩 될 수 있다는 뜻이다. 실제로 이런 데이터가 다량 존재했다. BTS나 BLACKPINK와 같은 인기 아이돌들의 비디오가 특히 그랬다. 조회수별로 데이터를 출력해보니 트렌딩 날짜만 다르게, 동일한 비디오가 쭉 출력됐다. (방탄만 10개가 쭉 나왔다..) 처음에는 distinct 키워드를 video_id 앞에 붙이면 해결이 될 거라고 생각해서 시도해봤지만 video_id 단일 데이터를 출력하는 것이 아니라, 트렌딩 날짜까지 출력하고자 했기에 통하지 않았다. (비디오 아이디는 같지만 트렌딩 날짜가 다르므로 다른 데이터로 인식되었음)
그래서 더 오랜 고민 끝에 나온 것이 group by 함수였다. group by 함수를 통해 video_id를 묶으니 최초 트렌딩 기준으로 하나의 데이터만 출력할 수 있었다.

### 회고
+
> 아직 많이 부족하지만 그래도 얼추 웹사이트같은 웹사이트를 만든 것 같아 뿌듯하다. 데이터베이스 과목들을 실습할 때 항상 공식처럼 employees 데이터를 사용했는데 처음으로 다른 데이터를 사용해서 너무 신기하고 재밌었다.
-
> 캐글 데이터를 가져오는 데에 많은 시간을 소비했다. 해결을 다 하고 슬랙을 보니 여러 gui 툴들이 있는 것 같았다. 나중에 또 사용하게 된다면 그런 툴들을 이용해서 가져오는 것이 더 시간면에서 경제적일 것 같다. (정신적으로도..) 유난히 특수문자가 많은 데이터를 사용해서 그런지 가져오는게 까다로웠던 것 같다.


